# 项目升级方案：提升匹配准确率与处理效率

**版本：** 1.2
**日期：** 2025-05-18
**负责人：** (待定)

## 1. 背景与目标

当前版本的 Spotify 歌单导入工具在处理大量歌曲，以及处理包含简繁体、中英文、括号信息等复杂文本的歌曲时，在匹配准确率和处理效率方面存在提升空间。本升级方案旨在通过引入并发API调用、改进匹配逻辑、增强文本处理能力等手段，显著提升用户体验和程序性能。

**主要目标：**

1.  **提高匹配准确率：** 更好地处理简繁体、中英文转换、轻微拼写错误、歌曲版本差异（如Live, Remix, Demo等）。
2.  **提升处理效率：** 缩短处理大量歌曲时的等待时间，特别是在网络IO方面。
3.  **增强程序健壮性：** 更好地处理API速率限制和各种预期外的输入。

## 2. 核心升级模块与策略

### 2.1 API 调用与速率限制处理 (效率提升核心)

*   **策略：** 从串行API调用改为并发/异步API调用，并遵守已知的API速率限制。
*   **已知API限制：** Spotify API 应用速率限制为 **25次请求/秒** (所有请求共享)。
*   **实施细节：**
    *   引入 `asyncio` 和 `aiohttp` (或 `httpx`) 库来替代 `spotipy` 中同步的 `requests` 调用，或者在 `spotipy` 的 `Spotify` 客户端外层封装异步请求逻辑。
        *   *备选方案：* 如果不想引入 `asyncio` 的复杂性，可以考虑使用线程池 (`concurrent.futures.ThreadPoolExecutor`) 来实现并发，但对于IO密集型任务，`asyncio` 通常更优。
    *   **并发控制：**
        *   实现一个可配置的并发数限制。鉴于 25次/秒 的限制，初始并发数可以设置在 **10-20之间**，并进行测试以找到最佳平衡点，避免短时间内脉冲式地超出限制。
        *   使用 `asyncio.Semaphore` 或类似机制来控制同时发出的请求数量。
        *   可以考虑实现一个请求队列和令牌桶/漏桶算法，以更平滑地将请求速率控制在25次/秒以内。
    *   **速率限制处理（`429 Too Many Requests`）：**
        *   在API调用逻辑中，捕获 `spotipy.SpotifyException` (或其他由异步库抛出的等效HTTP错误异常)。
        *   检查HTTP状态码是否为 `429`。
        *   如果响应头中包含 `Retry-After`，则异步等待指定秒数后重试。
        *   如果没有 `Retry-After`，则实现指数退避策略（例如，首次等待0.5秒，然后1秒，2秒...），并设置最大重试次数。
        *   记录速率限制事件和重试行为。
*   **影响：**
    *   **正面：** 大幅缩短处理歌曲列表的总时间，尤其是对于包含大量歌曲的列表，网络等待时间会被显著优化。25次/秒的限制相对较高，允许我们实现显著的并发提速。
    *   **挑战：** 增加了代码的复杂性；需要仔细设计和测试速率限制处理逻辑。即使限制较高，不良的并发策略仍可能导致临时超限。

### 2.2 歌曲搜索查询增强 (准确率提升)

*   **策略：** 优化 `sp.search()` 的查询参数 `q` 和 `limit`。
*   **实施细节：**
    *   **艺术家匹配扩展：**
        *   修改查询字符串构建逻辑，从仅使用 `parsed_song.artists[0]` 改为使用**前两位艺术家**（如果存在第二位）。
        *   例如：`q=f"track:{title} artist:{artist1} artist:{artist2}"` 或 `q=f"track:{title} artist:{artist1}"` （如果只有一位）。
        *   考虑如何更好地组合多个艺术家名以获得最佳搜索效果（例如，是否都放在 `artist:` 字段，或者尝试不同的组合查询）。
    *   **增加候选结果数量：**
        *   将 `sp.search()` 的 `limit` 参数从 `1` 调整为 `3` (或可配置的更高值，如 `5`)。这将为后续的本地匹配决策提供更多候选。
*   **影响：**
    *   **正面：** 为Spotify API提供更丰富的艺术家信息，可能有助于其返回更相关的初步结果；获取多个候选为本地进一步筛选提供了基础。
    *   **负面：** API响应时间可能略微增加（因为返回更多数据）；查询构造逻辑略微复杂化。

### 2.3 文本预处理与归一化 (准确率提升)

*   **策略：** 在进行字符串比较之前，对用户输入和从Spotify API获取的文本数据进行标准化处理。
*   **实施细节（应用于歌曲标题和艺术家名）：**
    *   **简繁体统一：** 使用 `opencc-python-reimplemented` 或 `langconv` 库，将所有中文文本统一转换为简体中文（或项目统一标准）。
    *   **大小写统一：** 将所有英文字母转换为小写。
    *   **全角/半角统一：** 将全角字符（尤其是标点和字母数字）转为半角。
    *   **去除/替换特定模式（首次匹配时，括号信息可选择性处理）：**
        *   定义一个可配置的正则表达式列表或关键词列表，用于去除或替换常见的、对核心身份识别影响不大的修饰词和模式。
        *   例如：`\(live.*?\)`、`\[remastered.*?\]`、`\(demo\)`、`\(acoustic\)`、`\(feat\..*?\)`、`\(.*soundtrack\)`、`explicit` 等。
        *   对于连字符 `-`、斜杠 `/`、与号 `&` 等分隔符，进行标准化处理（例如，统一替换为空格或特定分隔符）。
        *   去除首尾多余空格，并将连续的多个内部空格压缩为单个空格。
    *   **实现位置：** 创建一个通用的归一化函数，在 `search_song_on_spotify` 内部，对 `parsed_song` 的数据和从 `sp.search()` 返回的每个候选的相应字段进行处理。
*   **影响：**
    *   **正面：** 消除大量因格式、大小写、简繁体、常见修饰词导致的表面差异，为后续的相似度比较打下良好基础。
    *   **负面：** 增加本地CPU计算时间（文本处理开销）；归一化规则的定义和维护需要投入精力。

### 2.4 基于字符串相似度的两阶段匹配决策 (准确率提升核心)

*   **策略：** 在获取到多个（例如3个）经过初步查询的候选歌曲后，通过本地的、更细致的比较逻辑来选择最佳匹配，并引入两阶段处理括号内信息以提高精确度。
*   **实施细节：**
    1.  **第一阶段匹配（主要部分，忽略括号进行初步筛选）：**
        *   对用户输入的 `parsed_song.title` 和 `parsed_song.artists` 进行归一化（此阶段的归一化**去除或暂时忽略**括号及其内容）。
        *   对从Spotify返回的N个候选歌曲（例如N=3或5），同样对其标题和艺术家名进行"忽略括号"的归一化。
        *   使用字符串相似度算法（如 `fuzzywuzzy` 的 `WRatio` 或 `token_set_ratio`）分别计算标题相似度 (`title_score`) 和艺术家列表相似度 (`artist_score`)。
        *   为每个候选计算一个**初步综合得分**：例如 `weighted_score = (title_score * Wt) + (artist_score * Wa)`。
        *   筛选出初步综合得分超过某个较高阈值 `T1` 的候选，或取Top K个候选进入下一阶段。

    2.  **第二阶段匹配（精细化，重点考虑括号信息和其他细节）：**
        *   对于通过第一阶段筛选的候选歌曲：
            *   提取用户原始输入歌名（及艺术家名，如果适用）的括号内信息 (`user_bracket_info`) 和候选歌名（及艺术家名）原始文本的括号内信息 (`candidate_bracket_info`)。
            *   对这些括号内的信息也进行适当的归一化。
            *   计算 `user_bracket_info` 和 `candidate_bracket_info` 的相似度 (`bracket_score`)，或检查是否包含特定关键词（如 "live", "acoustic", "remix", "feat." 等）并据此打分。
            *   考虑其他细节差异，例如去除 "Live", "Remastered" 等常见后缀后的核心标题/艺术家名是否完全一致。
            *   根据这些精细化的比较结果，调整第一阶段的 `weighted_score`，得到一个**最终匹配得分**。
        *   从所有候选者中选择 `final_score` 最高且超过最终阈值 `T2` 的作为最佳匹配。

    3.  **`MatchedSong` 对象创建：** 使用最终选定的最佳匹配的原始Spotify数据来填充 `MatchedSong` 对象，以保留Spotify的官方命名。

*   **影响：**
    *   **正面：** 有望显著提升对歌曲版本、括号内别名等的匹配准确性。两阶段处理提供了更强的控制力。
    *   **负面：** 大幅增加本地CPU计算时间（多次相似度计算）；代码逻辑变得非常复杂，需要精心设计评分和决策机制、权重和阈值。

### 2.5 错误处理与日志增强

*   **策略：** 改进错误捕获和日志记录，便于调试和用户反馈。
*   **实施细节：**
    *   在 `main.py` 和各个核心模块中，对可能发生的异常（文件IO、API错误、配置错误、匹配逻辑错误）进行更细致的捕获。
    *   使用 Python 的 `logging` 模块代替简单的 `print` 到 `stderr`。
    *   允许通过环境变量或配置文件设置日志级别（DEBUG, INFO, WARNING, ERROR）。
    *   在 DEBUG 级别下，记录更详细的匹配过程信息，如归一化前后的文本、每个候选的相似度得分等。
    *   向用户报告时，提供更清晰的错误分类和可能的解决方案。

## 3. 预期成果

*   大幅减少因简繁体、中英文（部分）、常见后缀、括号信息等导致的匹配失败案例。
*   显著缩短处理500首及以上歌曲列表的总时间（通过并发API调用）。
*   用户能够获得更准确的播放列表。
*   程序对API错误和异常情况的处理更具韧性。

## 4. 实施步骤与优先级建议

1.  **高优先级（基础与效率）：**
    *   实现健壮的API速率限制处理逻辑（`429` 错误重试与退避，针对25次/秒优化）。
    *   引入并发/异步API调用框架（目标并发数10-20，带平滑发送机制）。
    *   增强日志系统。
2.  **中高优先级（核心准确率提升）：**
    *   实现文本预处理与归一化模块（简繁、大小写、去特定模式等，首次忽略括号）。
    *   修改 `sp.search()` 的 `limit` 为3（或更高）。
    *   实现第一阶段的基于字符串相似度的匹配（忽略括号信息）。
    *   扩展艺术家匹配至前两位。
3.  **中优先级（精细化准确率）：**
    *   实现第二阶段的匹配逻辑，专门处理和比较括号内的信息。
4.  **持续进行：**
    *   编写和完善单元测试、集成测试。
    *   根据测试结果和实际使用反馈，不断调优归一化规则、相似度算法参数、权重和阈值。

## 5. 风险与挑战

*   **并发编程的复杂性：** `asyncio` 的引入和正确的并发控制有一定学习曲线和调试难度。
*   **速率限制的精细控制：** 虽然25次/秒较宽松，但仍需良好控制以避免脉冲超限。
*   **匹配逻辑调优：** 找到普适的归一化规则、相似度权重和阈值组合，以适应各种音乐类型和命名习惯，是一个持续迭代的过程。
*   **性能与准确率的平衡：** 过度复杂的本地匹配逻辑会显著增加处理时间。
*   **外部库依赖：** 引入新库（如 `opencc`, `fuzzywuzzy`, `aiohttp`）增加了项目的依赖管理。

## 6. 未来展望 (可选)

*   允许用户交互式选择匹配结果（对于低置信度匹配）。
*   支持从更多来源导入歌曲（例如，其他音乐服务导出的列表）。
*   提供更丰富的报告格式（CSV, HTML）。
*   机器学习辅助匹配（对于非常大规模或复杂的场景）。
